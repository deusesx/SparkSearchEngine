{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Search Engine\n",
    "Done by Artur Samigullin\n",
    "\n",
    "This Notebook shows how to make indexing with a Spark Search Engine Library on a small use case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I. Indexing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Contexts\n",
    "First of all, to work with Spark Search Engine you need to import pyspark library and initialize SparkContext and SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext()\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlc = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.pythonVer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import SearchEngine class\n",
    "At this step you need to import SearchEngine class from SparkSearchEngineLib.SearchEngine package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from SparkSearchEngineLib.SearchEngine import SearchEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize instance of SearchEngine class\n",
    "You need to pass two parameters to SearchEngine constructor - SparkContext and SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "se = SearchEngine(sc,sqlc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index your dataset\n",
    "We assume that you made all preprocessing for your files, and we expect a folder that consists of textual files in format 'Token0 Token1 ... TokenN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "se.construct_index('./Dataset/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II. Use Search\n",
    "To use search you need to have an SearchEngine instance with constructed index. You can make it with *search( )* method.  \n",
    "*search( )* method has one parameter - preprocessed query string with format 'Token0 Token1 ... TokenN'  \n",
    "Method returns a list of links(filenames) with number of hits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.stem import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer('english')\n",
    "from nltk import wordpunct_tokenize\n",
    "\n",
    "import re\n",
    "punctStr = re.compile(r'|'.join([re.escape(x) for x in string.punctuation]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_query(query_string):\n",
    "    query = re.sub(punctStr, '', ' '.join( [ snowball_stemmer.stem(x) for x in wordpunct_tokenize(query_string)]))\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_str = preprocess_query('Alice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['file:/Users/deusesx/Projects/P&MP/Upload/Dataset/carroll-alice.txt has number of hits: 398',\n",
       " 'file:/Users/deusesx/Projects/P&MP/Upload/Dataset/edgeworth-parents.txt has number of hits: 2',\n",
       " 'file:/Users/deusesx/Projects/P&MP/Upload/Dataset/chesterton-thursday.txt has number of hits: 1']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find = se.search(q_str)\n",
    "find.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q_str2 = preprocess_query('Cheshire Cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['file:/Users/deusesx/Projects/P&MP/Upload/Dataset/carroll-alice.txt has number of hits: 57',\n",
       " 'file:/Users/deusesx/Projects/P&MP/Upload/Dataset/chesterton-ball.txt has number of hits: 8',\n",
       " 'file:/Users/deusesx/Projects/P&MP/Upload/Dataset/edgeworth-parents.txt has number of hits: 7',\n",
       " 'file:/Users/deusesx/Projects/P&MP/Upload/Dataset/chesterton-brown.txt has number of hits: 6',\n",
       " 'file:/Users/deusesx/Projects/P&MP/Upload/Dataset/whitman-leaves.txt has number of hits: 3',\n",
       " 'file:/Users/deusesx/Projects/P&MP/Upload/Dataset/melville-moby_dick.txt has number of hits: 3',\n",
       " 'file:/Users/deusesx/Projects/P&MP/Upload/Dataset/bryant-stories.txt has number of hits: 2',\n",
       " 'file:/Users/deusesx/Projects/P&MP/Upload/Dataset/shakespeare-macbeth.txt has number of hits: 2',\n",
       " 'file:/Users/deusesx/Projects/P&MP/Upload/Dataset/chesterton-thursday.txt has number of hits: 2',\n",
       " 'file:/Users/deusesx/Projects/P&MP/Upload/Dataset/austen-persuasion.txt has number of hits: 1']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_2 = se.search(q_str2)\n",
    "find_2.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III. Files Manipulation\n",
    "You can store your index in a *parquet* format. To make this just use *save_index( )* method.  \n",
    "*save_index( )* method has one parameter - string with filename.  \n",
    "Note that if filename is already exists, it will be overwritten by *save_index( )* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "se.save_index('index.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "se2 = SearchEngine(sc, sqlc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load index from *parquet* format with *load_index( )* method.  \n",
    "*load_index( )* method takes one parameter - filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "se2.load_index('index.parquet')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
